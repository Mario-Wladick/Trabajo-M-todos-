# PASO 5: AN√ÅLISIS COMPARATIVO FINAL
# Consolidaci√≥n de resultados y conclusiones del proyecto

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo profesional
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# =============================================
# 1. CONSOLIDACI√ìN DE RESULTADOS
# =============================================

def consolidate_results():
    """Consolida todos los resultados obtenidos"""
    
    print("üìä PASO 5: AN√ÅLISIS COMPARATIVO FINAL")
    print("=" * 55)
    print(f"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print(f"üéØ Proyecto: M√©todos de Optimizaci√≥n en Regresi√≥n")
    print(f"üìà Dataset: Empresas Agroindustriales de Ica (494 empresas)")
    
    # Resultados de todos los m√©todos probados
    results_summary = {
        'M√©todo': [
            'Regresi√≥n Lineal (Baseline)',
            'Random Forest (Sin transformar)',
            'Random Forest + Log Transform + Optuna'
        ],
        'R¬≤ Train': [
            0.8980,      # Regresi√≥n lineal
            0.0632,      # Random Forest original
            0.9763       # Random Forest + Log
        ],
        'R¬≤ Test': [
            -16737.2072, # Regresi√≥n lineal  
            -1605.5209,  # Random Forest original
            0.9987       # Random Forest + Log
        ],
        'RMSE Test (S/)': [
            195_455_534, # Regresi√≥n lineal
            60_553_142,  # Random Forest original
            54_013       # Random Forest + Log
        ],
        'Tiempo Entrenamiento': [
            '<1 segundo',
            '~50 segundos',
            '~180 segundos'
        ],
        'Viable': [
            '‚ùå No',
            '‚ùå No', 
            '‚úÖ S√≠'
        ]
    }
    
    df_results = pd.DataFrame(results_summary)
    
    print(f"\nüìã RESUMEN COMPARATIVO DE M√âTODOS")
    print("-" * 80)
    print(df_results.to_string(index=False))
    
    return df_results

# =============================================
# 2. AN√ÅLISIS DE TRANSFORMACI√ìN DE DATOS
# =============================================

def analyze_data_transformation():
    """Analiza el impacto de la transformaci√≥n logar√≠tmica"""
    
    print(f"\nüîÑ AN√ÅLISIS DE TRANSFORMACI√ìN DE DATOS")
    print("-" * 50)
    
    # Datos de transformaci√≥n (obtenidos anteriormente)
    transformation_impact = {
        'M√©trica': ['M√≠nimo', 'M√°ximo', 'Media', 'Std Dev', 'Coef. Variaci√≥n'],
        'Datos Originales': [
            'S/ 742,500',
            'S/ 13,365,000,000', 
            'S/ 29,340,774',
            'S/ 601,274,319',
            '2,049.3%'
        ],
        'Datos Log-Transformados': [
            '13.52',
            '23.32',
            '13.75', 
            '0.91',
            '6.6%'
        ],
        'Mejora': [
            '-',
            '-',
            '-',
            '660,000x menor',
            '310x mejor'
        ]
    }
    
    df_transform = pd.DataFrame(transformation_impact)
    print(df_transform.to_string(index=False))
    
    print(f"\nüí° CONCLUSIONES DE LA TRANSFORMACI√ìN:")
    print("   ‚Ä¢ Transformaci√≥n logar√≠tmica fue CLAVE para el √©xito")
    print("   ‚Ä¢ Redujo variabilidad extrema 310 veces") 
    print("   ‚Ä¢ Permiti√≥ que Random Forest encontrara patrones")
    print("   ‚Ä¢ Sin transformaci√≥n: R¬≤ negativo")
    print("   ‚Ä¢ Con transformaci√≥n: R¬≤ = 99.87%")

# =============================================
# 3. AN√ÅLISIS DE OPTUNA
# =============================================

def analyze_optuna_optimization():
    """Analiza el proceso de optimizaci√≥n con Optuna"""
    
    print(f"\nüîç AN√ÅLISIS DE OPTIMIZACI√ìN CON OPTUNA")
    print("-" * 45)
    
    # Hiperpar√°metros optimizados (del resultado anterior)
    optuna_results = {
        'Hiperpar√°metro': [
            'n_estimators',
            'max_depth', 
            'min_samples_split',
            'min_samples_leaf',
            'max_features',
            'bootstrap'
        ],
        'Valor √ìptimo': [
            '150',
            '16',
            '16', 
            '10',
            'sqrt',
            'True'
        ],
        'Rango Explorado': [
            '50-300',
            '5-20',
            '2-15',
            '1-8', 
            'sqrt, log2',
            'True, False'
        ],
        'Impacto': [
            'Alto',
            'Medio',
            'Medio',
            'Bajo',
            'Alto', 
            'Medio'
        ]
    }
    
    df_optuna = pd.DataFrame(optuna_results)
    print(df_optuna.to_string(index=False))
    
    print(f"\nüéØ BENEFICIOS DE OPTUNA:")
    print("   ‚Ä¢ Explor√≥ 50 combinaciones de hiperpar√°metros autom√°ticamente")
    print("   ‚Ä¢ Encontr√≥ configuraci√≥n √≥ptima en ~3 minutos")
    print("   ‚Ä¢ TPE Sampler: enfoque inteligente, no fuerza bruta")
    print("   ‚Ä¢ Cross-validation: asegur√≥ robustez del modelo")
    print("   ‚Ä¢ Mejor RMSE: 0.2898 en escala logar√≠tmica")

# =============================================
# 4. AN√ÅLISIS DE FEATURES IMPORTANTES
# =============================================

def analyze_feature_importance():
    """Analiza las variables m√°s importantes del modelo final"""
    
    print(f"\nüîç VARIABLES M√ÅS IMPORTANTES (MODELO FINAL)")
    print("-" * 55)
    
    # Feature importance del modelo final
    features_importance = {
        'Variable': [
            'valor_estimado_minimo_venta',
            'tamanio_emp_encoded', 
            'exporta_encoded',
            'ciiu',
            'descciiu_encoded',
            'distrito_encoded',
            'provincia_encoded'
        ],
        'Importancia': [
            0.537,
            0.288,
            0.113,
            0.035,
            0.018,
            0.007,
            0.002
        ],
        'Porcentaje': [
            '53.7%',
            '28.8%', 
            '11.3%',
            '3.5%',
            '1.8%',
            '0.7%',
            '0.2%'
        ],
        'Interpretaci√≥n Empresarial': [
            'Ventas m√≠nimas predicen ventas m√°ximas',
            'Tama√±o de empresa es factor clave',
            'Actividad exportadora es relevante', 
            'C√≥digo de actividad econ√≥mica',
            'Tipo espec√≠fico de actividad',
            'Ubicaci√≥n distrital menor impacto',
            'Provincia tiene m√≠nimo impacto'
        ]
    }
    
    df_features = pd.DataFrame(features_importance)
    print(df_features.to_string(index=False))
    
    print(f"\nüíº CONCLUSION:")
    print("   ‚Ä¢ TOP 3 variables explican 79.8% de la predicci√≥n")
    print("   ‚Ä¢ Ventas m√≠nimas son el mejor predictor (l√≥gico empresarialmente)")
    print("   ‚Ä¢ Tama√±o empresarial define capacidad de ventas") 
    print("   ‚Ä¢ Exportar indica empresa m√°s sofisticada")
    print("   ‚Ä¢ Ubicaci√≥n geogr√°fica tiene impacto m√≠nimo")

# =============================================
# 5. VISUALIZACI√ìN COMPARATIVA
# =============================================

def create_comparative_visualization():
    """Crea visualizaci√≥n comparativa de todos los m√©todos"""
    
    print(f"\nüìà GENERANDO VISUALIZACI√ìN COMPARATIVA...")
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Comparaci√≥n R¬≤ 
    ax1 = axes[0, 0]
    methods = ['Reg. Lineal', 'RF Original', 'RF + Log + Optuna']
    r2_values = [-16737.2072, -1605.5209, 0.9987]
    colors = ['red', 'orange', 'green']
    
    # Usar escala logar√≠tmica para mostrar la mejora
    ax1.bar(methods, [abs(x) if x < 0 else x for x in r2_values], color=colors, alpha=0.7)
    ax1.set_ylabel('|R¬≤| (Escala log)')
    ax1.set_title('üìä Comparaci√≥n R¬≤ por M√©todo', fontweight='bold', fontsize=14)
    ax1.set_yscale('log')
    ax1.grid(True, alpha=0.3)
    
    # A√±adir valores en las barras
    for i, v in enumerate(r2_values):
        if v > 0:
            ax1.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')
        else:
            ax1.text(i, abs(v), f'{v:.0f}', ha='center', va='bottom', fontweight='bold')
    
    # 2. Evoluci√≥n del RMSE
    ax2 = axes[0, 1] 
    rmse_values = [195_455_534, 60_553_142, 54_013]
    ax2.plot(methods, rmse_values, 'o-', linewidth=3, markersize=8, color='blue')
    ax2.set_ylabel('RMSE (S/)')
    ax2.set_title('üìâ Evoluci√≥n del RMSE', fontweight='bold', fontsize=14)
    ax2.grid(True, alpha=0.3)
    ax2.tick_params(axis='x', rotation=45)
    
    # Formato de n√∫meros
    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'S/ {x/1e6:.0f}M'))
    
    # 3. Feature Importance (Top 5)
    ax3 = axes[1, 0]
    features = ['valor_min_venta', 'tamanio_emp', 'exporta', 'ciiu', 'descciiu']
    importance = [0.537, 0.288, 0.113, 0.035, 0.018]
    
    bars = ax3.barh(features, importance, color='skyblue', alpha=0.8)
    ax3.set_xlabel('Importancia')
    ax3.set_title('üîç Top 5 Variables M√°s Importantes', fontweight='bold', fontsize=14)
    ax3.grid(True, alpha=0.3)
    
    # A√±adir porcentajes
    for i, v in enumerate(importance):
        ax3.text(v + 0.01, i, f'{v*100:.1f}%', va='center', fontweight='bold')
    
    # 4. Impacto de la transformaci√≥n
    ax4 = axes[1, 1]
    transform_metrics = ['Coef. Variaci√≥n', 'R¬≤ Final', 'RMSE Final']
    before = [2049.3, -1605.5, 60_553_142/1e6]  # Valores antes
    after = [6.6, 0.9987, 54_013/1e6]  # Valores despu√©s
    
    x = np.arange(len(transform_metrics))
    width = 0.35
    
    ax4.bar(x - width/2, [2049.3, 0, 60.6], width, label='Sin Transformaci√≥n', 
            color='red', alpha=0.7)
    ax4.bar(x + width/2, [6.6, 99.87, 0.054], width, label='Con Log Transform', 
            color='green', alpha=0.7)
    
    ax4.set_ylabel('Valor de M√©trica')
    ax4.set_title('üîÑ Impacto de Transformaci√≥n Log', fontweight='bold', fontsize=14)
    ax4.set_xticks(x)
    ax4.set_xticklabels(['CV (%)', 'R¬≤ (%)', 'RMSE (M S/)'])
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# =============================================
# 6. CONCLUSIONES Y RECOMENDACIONES
# =============================================

def generate_conclusions():
    """Genera conclusiones finales del proyecto"""
    
    print(f"\nüéØ RESUMEN")
    print("=" * 30)
    print("   ‚Ä¢ Transformaci√≥n logar√≠tmica resolvi√≥ problema de outliers")
    print("   ‚Ä¢ Random Forest + Optuna logr√≥ R¬≤ = 99.87%")
    print("   ‚Ä¢ Proyecto t√©cnicamente exitoso")

# =============================================
# 7. FUNCI√ìN PRINCIPAL
# =============================================

def main():
    """Ejecuta an√°lisis comparativo completo"""
    
    # 1. Consolidar resultados
    df_results = consolidate_results()
    
    # 2. Analizar transformaci√≥n
    analyze_data_transformation()
    
    # 3. Analizar Optuna
    analyze_optuna_optimization()
    
    # 4. Analizar features
    analyze_feature_importance()
    
    # 5. Crear visualizaciones
    create_comparative_visualization()
    
    # 6. Conclusiones finales
    generate_conclusions()
    
    print(f"\nüìä AN√ÅLISIS T√âCNICO COMPLETADO")
  
    
    return df_results

# =============================================
# 8. EJECUCI√ìN
# =============================================

if __name__ == "__main__":
    results_df = main()